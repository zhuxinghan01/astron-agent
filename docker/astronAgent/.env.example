# Docker Compose environment variable configuration example
# Copy this file to .env and modify the configuration as needed

# ============================================================================
# Middleware Configuration
# ============================================================================

# PostgreSQL Configuration
POSTGRES_USER=spark
POSTGRES_PASSWORD=spark123
# PostgreSQL connection configuration. If deploying middleware independently, modify the following configuration; otherwise, use default
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# MySQL Configuration
MYSQL_ROOT_PASSWORD=root123
# MySQL connection configuration. If deploying middleware independently, modify the following configuration; otherwise, use default
MYSQL_USER=root
MYSQL_PASSWORD=${MYSQL_ROOT_PASSWORD:-root123}
MYSQL_HOST=mysql
MYSQL_PORT=3306
MYSQL_URL=jdbc:mysql://mysql:3306/astron_console

# Redis Configuration
# REDIS_PASSWORD=your-redis-password # Optional, uncomment to enable authentication
REDIS_DATABASE=0
REDIS_IS_CLUSTER=false
REDIS_CLUSTER_ADDR=
REDIS_EXPIRE=3600
# Redis connection configuration. If deploying middleware independently, modify the following configuration; otherwise, use default
REDIS_ADDR=redis:6379
REDIS_HOST=redis
REDIS_PORT=6379

# Elasticsearch Configuration
ELASTICSEARCH_SECURITY_ENABLED=false
ES_JAVA_OPTS='-Xms512m -Xmx512m'

# Kafka Configuration
EXPOSE_KAFKA_PORT=9092
KAFKA_REPLICATION_FACTOR=1
KAFKA_CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk
KAFKA_TIMEOUT=60
# Kafka connection configuration. If deploying middleware independently, modify the following configuration; otherwise, use default
KAFKA_SERVERS=kafka:29092

# MinIO Configuration
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123
EXPOSE_MINIO_PORT=19000
EXPOSE_MINIO_CONSOLE_PORT=19001

# OSS Configuration (can be replaced with your own OSS system)
OSS_TYPE=s3
OSS_ENDPOINT=http://minio:9000
OSS_ACCESS_KEY_ID=${MINIO_ROOT_USER:-minioadmin}
OSS_ACCESS_KEY_SECRET=${MINIO_ROOT_PASSWORD:-minioadmin123}
OSS_BUCKET_NAME=
OSS_TTL=157788000
OSS_DOWNLOAD_HOST=http://minio:9000

# OTLP Address
OTLP_ENABLE=0
OTLP_ENDPOINT=127.0.0.1:4317
OTLP_METRIC_TIMEOUT=3000
OTLP_METRIC_EXPORT_INTERVAL_MILLIS=3000
OTLP_METRIC_EXPORT_TIMEOUT_MILLIS=3000
# Tracing Configuration
OTLP_TRACE_TIMEOUT=3000
OTLP_TRACE_MAX_QUEUE_SIZE=2048
OTLP_TRACE_SCHEDULE_DELAY_MILLIS=3000
OTLP_TRACE_MAX_EXPORT_BATCH_SIZE=2048
OTLP_TRACE_EXPORT_TIMEOUT_MILLIS=3000

# ============================================================================
# astron-agent Application Port Configuration
# ============================================================================

# Core Service Port Configuration
CORE_TENANT_PORT=5052
CORE_DATABASE_PORT=7990
CORE_RPA_PORT=17198
CORE_LINK_PORT=18888
CORE_AITOOLS_PORT=18668
CORE_AGENT_PORT=17870
CORE_KNOWLEDGE_PORT=20010
CORE_WORKFLOW_PORT=7880

# Console Frontend Casdoor Configuration
# These variables are prioritized over VITE_CASDOOR_* equivalents in frontend builds
CONSOLE_CASDOOR_URL=http://your-casdoor-server:8000
CONSOLE_CASDOOR_ID=your-casdoor-client-id
CONSOLE_CASDOOR_APP=your-casdoor-app-name
CONSOLE_CASDOOR_ORG=your-casdoor-org-name

# ============================================================================
# Component-specific Environment Variable Configuration
# ============================================================================

# - Tenant-specific Configuration
# Database type
DATABASE_DB_TYPE=mysql
# Database username
DATABASE_USERNAME=${MYSQL_USER:-root}
# Database password
DATABASE_PASSWORD=${MYSQL_PASSWORD:-root123}
# Database (ip:port)/database name
DATABASE_URL=(mysql:3306)/tenant
# Database maximum connections
DATABASE_MAX_OPEN_CONNS=5
# Database maximum idle connections
DATABASE_MAX_IDLE_CONNS=5
# Log path
LOG_PATH=log.txt

# - DATABASE-specific Configuration
DATABASE_POSTGRES_DATABASE=sparkdb_manager

# - RPA-specific Configuration
XIAOWU_RPA_TASK_CREATE_URL=https://newapi.iflyrpa.com/api/rpa-openapi/workflows/execute-async
XIAOWU_RPA_TASK_QUERY_URL=https://newapi.iflyrpa.com/api/rpa-openapi/executions

# - Link-specific Configuration
LINK_MYSQL_DB=spark-link

# - Agent-specific Configuration
# Service configuration
SERVICE_HOST=0.0.0.0
SERVICE_WORKERS=1
SERVICE_RELOAD=false
SERVICE_WS_PING_INTERVAL=false
SERVICE_WS_PING_TIMEOUT=false
# MySQL Configuration
AGENT_MYSQL_DB=agent
# ELK upload configuration
UPLOAD_NODE_TRACE=true
UPLOAD_METRICS=true
# Kafka
AGENT_KAFKA_TOPIC=spark-agent-builder
# Link Service URLs
GET_LINK_URL=http://core-link:18888/api/v1/tools
VERSIONS_LINK_URL=http://core-link:18888/api/v1/tools/versions
RUN_LINK_URL=http://core-link:18888/api/v1/tools/http_run
# Workflow Service URLs
GET_WORKFLOWS_URL=http://core-workflow:${CORE_WORKFLOW_PORT:-7880}/sparkflow/v1/protocol/get
WORKFLOW_SSE_BASE_URL=http://core-workflow:${CORE_WORKFLOW_PORT:-7880}/workflow/v1
# Knowledge Service URLs
CHUNK_QUERY_URL=http://core-knowledge:${CORE_KNOWLEDGE_PORT:-20010}/knowledge/v1/chunk/query
# MCP Plugin URLs
LIST_MCP_PLUGIN_URL=http://core-link:18888/api/v1/mcp/tool_list
RUN_MCP_PLUGIN_URL=http://core-link:18888/api/v1/mcp/call_tool
# Application authentication configuration
APP_AUTH_HOST=core-tenant:${CORE_TENANT_PORT:-5052}
APP_AUTH_PROT=http
APP_AUTH_API_KEY=7b709739e8da44536127a333c7603a83
APP_AUTH_SECRET=NjhmY2NmM2NkZDE4MDFlNmM5ZjcyZjMy

# - Knowledge-specific Configuration
RAGFLOW_BASE_URL=http://your-ragflow-url/
RAGFLOW_API_TOKEN=your-ragflow-token
RAGFLOW_TIMEOUT=60
RAGFLOW_DEFAULT_GROUP=your-default-group
XINGHUO_DATASET_ID=

# - Workflow-specific Configuration
WORKFLOW_MYSQL_DB=workflow
WORKFLOW_KAFKA_TOPIC=spark-agent-builder
RUNTIME_ENV=dev

# ============================================================================
# Console Module Configuration
# ============================================================================
# Domain config for console module
CONSOLE_DOMAIN=https://your.deployment.domain

# S3/MinIO Configuration for Console backend
OSS_BUCKET_CONSOLE=console
OSS_PRESIGN_EXPIRY_SECONDS_CONSOLE=600

# Redis Configuration for Console backend
REDIS_DATABASE_CONSOLE=1

# OAuth2 Configuration for Console Backend Api Server (as OAuth2 Resource Server)
OAUTH2_ISSUER_URI=${CONSOLE_CASDOOR_URL:-http://auth-server:8000}
OAUTH2_JWK_SET_URI=${CONSOLE_CASDOOR_URL:-http://auth-server:8000}/.well-known/jwks
OAUTH2_AUDIENCE=${CONSOLE_CASDOOR_ID:-your-oauth2-client-id}

# Open Platform API Configuration
# You can create an app after registering an account in the console website to obtain the following parameters. See: https://console.xfyun.cn/
# NOTE! The following three values ​​are required for the service to run properly:
PLATFORM_APP_ID=your-app-id
PLATFORM_API_KEY=your-api-key
PLATFORM_API_SECRET=your-api-secret
# You can get your own API key and secret on the iFLYTEK Open Platform official website, and purchase API usage or get free quota.
# SPARK LLM API: https://xinghuo.xfyun.cn/sparkapi
# LFASR API: https://www.xfyun.cn/services/lfasr
# IMAGE-GEN API: https://www.xfyun.cn/services/wtop
# For Spark LLM API, there will be an additional API password that needs to be obtained from the console website (https://console.xfyun.cn/services/bm4):
SPARK_API_PASSWORD=your-api-password

SPARK_APP_ID=${PLATFORM_APP_ID}
SPARK_API_KEY=${PLATFORM_API_KEY}
SPARK_API_SECRET=${PLATFORM_API_SECRET}
SPARK_LFASR_APPID=${PLATFORM_APP_ID}
SPARK_LFASR_KEY=${PLATFORM_API_KEY}
SPARK_IMAGE_APP_ID=${PLATFORM_APP_ID}
SPARK_IMAGE_API_KEY=${PLATFORM_API_KEY}
SPARK_IMAGE_API_SECRET=${PLATFORM_API_SECRET}

# Console Hub WeChat platform Configuration
WECHAT_COMPONENT_APPID=your-wechat-component-appid
WECHAT_COMPONENT_SECRET=your-wechat
WECHAT_TOKEN=your-wechat-token
WECHAT_ENCODING_AES_KEY=your-wechat-encoding-aes-key

# core-workflow module's service-to-service API calls
WORKFLOW_CHAT_URL=http://core-workflow:${CORE_WORKFLOW_PORT:-7880}/workflow/v1/chat/completions
WORKFLOW_DEBUG_URL=http://core-workflow:${CORE_WORKFLOW_PORT:-7880}/workflow/v1/debug/chat/completions
WORKFLOW_RESUME_URL=http://core-workflow:${CORE_WORKFLOW_PORT:-7880}/workflow/v1/resume

# Common appId, requiring Spark Model authorization
COMMON_APPID=${PLATFORM_APP_ID}
COMMON_APIKEY=${PLATFORM_API_KEY}
COMMON_API_SECRET=${PLATFORM_API_SECRET}

# Toolkit tenant systemWhen calling the flow system, it is necessary.
# The value here is pre-written to the database when the core-tenant component is started, see: core/tenant/sql/tenant.sql
TENANT_ID=680ab54f
TENANT_KEY=7b709739e8da44536127a333c7603a83
TENANT_SECRET=NjhmY2NmM2NkZDE4MDFlNmM5ZjcyZjMy

# Toolkit Admin uid The plugin created by this user ID defaults to the official plugin
ADMIN_UID=9999

APP_URL=http://core-tenant:${CORE_TENANT_PORT:-5052}/v2/app
KNOWLEDGE_URL=http://core-knowledge:${CORE_KNOWLEDGE_PORT:-20010}/knowledge
TOOL_URL=http://core-link:18888
WORKFLOW_URL=http://core-workflow:${CORE_WORKFLOW_PORT:-7880}
SPARK_DB_URL=http://core-memory:${CORE_MEMORY_PORT:-7990}
LOCAL_MODEL_URL=http://10.103.240.12:33777

# MaaS Platform Configuration
MAAS_APP_ID=${PLATFORM_APP_ID}
MAAS_API_KEY=${PLATFORM_API_KEY}
MAAS_API_SECRET=${PLATFORM_API_SECRET}

MAAS_CONSUMER_ID=${TENANT_ID}
MAAS_CONSUMER_KEY=${TENANT_KEY}
MAAS_CONSUMER_SECRET=${TENANT_SECRET}

MAAS_WORKFLOW_VERSION=http://127.0.0.1:8080/workflow/version
MAAS_SYNCHRONIZE_WORK_FLOW=http://127.0.0.1:8080/workflow
MAAS_PUBLISH=http://127.0.0.1:8080/workflow/publish
MAAS_CLONE_WORK_FLOW=http://127.0.0.1:8080/workflow/internal-clone
MAAS_GET_INPUTS=http://127.0.0.1:8080/workflow/get-inputs-info
MAAS_CAN_PUBLISH_URL=http://127.0.0.1:8080/workflow/can-publish
MAAS_PUBLISH_API=http://core-workflow:${CORE_WORKFLOW_PORT:-7880}/workflow/v1/publish
MAAS_AUTH_API=http://core-workflow:${CORE_WORKFLOW_PORT:-7880}/workflow/v1/auth
MAAS_MCP_REGISTER=http://127.0.0.1:8080/workflow/release
MAAS_WORKFLOW_CONFIG=http://127.0.0.1:8080/workflow/get-flow-advanced-config
BOT_API_CBM_BASE_URL=ws(s)://spark-openapi.cn-huabei-1.xf-yun.com
BOT_API_MAAS_BASE_URL=http(s)://xingchen-api.xf-yun.com

TENANT_CREATE_APP=http://core-tenant:${CORE_TENANT_PORT:-5052}/v2/app
TENANT_GET_APP_DETAIL=http://core-tenant:${CORE_TENANT_PORT:-5052}/v2/app/details

# deepseek config
DEEPSEEK_URL=https://api.deepseek.com/chat/completions
DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}

# ============================================================================
# Other Configuration
# ============================================================================

# Nginx configuration
EXPOSE_NGINX_PORT=10080

# Service availability zone (dx, hf, gz)
SERVICE_LOCATION=hf

# Health check configuration
HEALTH_CHECK_INTERVAL=30s
HEALTH_CHECK_TIMEOUT=10s
HEALTH_CHECK_RETRIES=60

# Network configuration
NETWORK_SUBNET=172.20.0.0/16

